# Neural Language Models


This repository contains neural language model implementations trained and tested on Penn Treebank.

1. **Multi-layer LSTM with Dropout**: The link to the notebook is [here](https://github.com/pranav-ust/nlm/blob/master/notebooks/LSTM%20Language%20Model.ipynb). It receives perplexity around 80.6 on test set on default parameters.
2. **Gated Convolutional Networks with Residual Connections**: The link to the notebook is [here](https://github.com/pranav-ust/nlm/blob/master/notebooks/Gated%20Convolutional%20Networks.ipynb). It receives perplexity around 70.9 on test set on default parameters.

## Requirements

You will need Pytorch 0.4 and Python 3.5 to run this.


## How to run

1. For LSTM code simply run like `python3 rnn.py`
2. For GCNN code simply run like `python3 cnn.py`


